{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1QmpKUgW2xdl"
   },
   "source": [
    "Run the next code cell without changes to load the training and validation sets in `X_train`, `X_valid`, `y_train`, and `y_valid`.  The test set is loaded in `X_test`.\n",
    "\n",
    "Make sure to copy the file path of X_full which is train.csv and X_test_full which is test.csv before running the cell\n",
    "Upload the dataset in your notebook before starting to run all the cells.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "OvGj9UcuWUZ1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the data\n",
    "X_full = pd.read_csv('train.csv', index_col='Id')\n",
    "X_test_full = pd.read_csv('test.csv', index_col='Id')\n",
    "\n",
    "# Remove rows with missing target, separate target from predictors\n",
    "X_full_target = X_full.dropna(axis=0, subset=['SalePrice'])\n",
    "y = X_full_target.SalePrice\n",
    "X_full_feature = X_full.drop(['SalePrice'], axis=1)\n",
    "\n",
    "# To keep things simple, we'll use only numerical predictors\n",
    "X = X_full_feature.select_dtypes(exclude=['object'])\n",
    "X_test = X_test_full.select_dtypes(exclude=['object'])\n",
    "\n",
    "# Break off validation set from training data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
    "                                                      random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZbcapCQtu1HQ"
   },
   "source": [
    "Use the next code cell to print the first five rows of the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "executionInfo": {
     "elapsed": 585,
     "status": "ok",
     "timestamp": 1718654140525,
     "user": {
      "displayName": "Nischay Patel",
      "userId": "06088096062725078193"
     },
     "user_tz": -330
    },
    "id": "nhF66U1Mu6fB",
    "outputId": "f5b25511-f571-47bf-eb5f-941f8aaa696a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>90</td>\n",
       "      <td>67.0</td>\n",
       "      <td>8777</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1900</td>\n",
       "      <td>2003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1084</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>190</td>\n",
       "      <td>60.0</td>\n",
       "      <td>10800</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1900</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>220</td>\n",
       "      <td>114</td>\n",
       "      <td>210</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>20</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8767</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2005</td>\n",
       "      <td>2005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>60</td>\n",
       "      <td>82.0</td>\n",
       "      <td>11287</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1989</td>\n",
       "      <td>1989</td>\n",
       "      <td>340.0</td>\n",
       "      <td>421</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>575</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>196</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1402</th>\n",
       "      <td>60</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7415</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2004</td>\n",
       "      <td>2004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>759</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>398</td>\n",
       "      <td>100</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "Id                                                                            \n",
       "922           90         67.0     8777            5            7       1900   \n",
       "521          190         60.0    10800            4            7       1900   \n",
       "402           20         65.0     8767            7            5       2005   \n",
       "281           60         82.0    11287            7            6       1989   \n",
       "1402          60         62.0     7415            6            5       2004   \n",
       "\n",
       "      YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  GarageArea  \\\n",
       "Id                                                      ...               \n",
       "922           2003         0.0        1084           0  ...           0   \n",
       "521           2000         0.0           0           0  ...           0   \n",
       "402           2005         0.0          24           0  ...         400   \n",
       "281           1989       340.0         421           0  ...         575   \n",
       "1402          2004         0.0         759           0  ...         398   \n",
       "\n",
       "      WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  \\\n",
       "Id                                                                     \n",
       "922            0           70              0          0            0   \n",
       "521          220          114            210          0            0   \n",
       "402            0            0              0          0            0   \n",
       "281            0           84              0        196            0   \n",
       "1402         100           75              0          0            0   \n",
       "\n",
       "      PoolArea  MiscVal  MoSold  YrSold  \n",
       "Id                                       \n",
       "922          0        0       9    2008  \n",
       "521          0        0       8    2008  \n",
       "402          0        0       7    2006  \n",
       "281          0        0       1    2007  \n",
       "1402         0        0       4    2008  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pmaE4aFXxUDM"
   },
   "source": [
    "You can already see a few missing values in the first several rows.  In the next step, you'll obtain a more comprehensive understanding of the missing values in the dataset.\n",
    "\n",
    "# Step 1: Preliminary investigation\n",
    "\n",
    "Run the code cell below without changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "oyfhEl6AxTne"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1168, 36)\n",
      "LotFrontage    209\n",
      "MasVnrArea       8\n",
      "GarageYrBlt     61\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Shape of training data (num_rows, num_columns)\n",
    "print(X_train.shape)\n",
    "\n",
    "# Number of missing values in each column of training data\n",
    "missing_val_count_by_column = (X_train.isnull().sum())\n",
    "print(missing_val_count_by_column[missing_val_count_by_column > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vEVNyWjlxYBn"
   },
   "source": [
    "### Part A\n",
    "\n",
    "Use the above output to answer the questions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "BMH4NFvlxWM8"
   },
   "outputs": [],
   "source": [
    "# Fill in the line below: How many rows are in the training data?\n",
    "num_rows = 1168\n",
    "\n",
    "# Fill in the line below: How many columns in the training data\n",
    "# have missing values?\n",
    "num_cols_with_missing = 3\n",
    "\n",
    "# Fill in the line below: How many missing entries are contained in\n",
    "# all of the training data?\n",
    "tot_missing = 278"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PGmTtY51yGC8"
   },
   "source": [
    "### Part B\n",
    "Considering your answers above, what do you think is likely the best approach to dealing with the missing values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F3J2kB5Fx8vI"
   },
   "source": [
    "Since there are relatively few missing entries in the data (the column with the greatest percentage of missing values is missing less than 20% of its entries), we can expect that dropping columns is unlikely to yield good results. This is because we'd be throwing away a lot of valuable data, and so imputation will likely perform better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ab2Mvv-Kx_ii"
   },
   "source": [
    "To compare different approaches to dealing with missing values, you'll use the same `score_dataset()` function from the tutorial.  This function reports the [mean absolute error](https://en.wikipedia.org/wiki/Mean_absolute_error) (MAE) from a random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O8w1Mra9yAKo"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Function for comparing different approaches\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zSqgEi85yKiw"
   },
   "source": [
    "# Step 2: Drop columns with missing values\n",
    "\n",
    "In this step, you'll preprocess the data in `X_train` and `X_valid` to remove columns with missing values.  Set the preprocessed DataFrames to `reduced_X_train` and `reduced_X_valid`, respectively.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "kutf7lIVxcuw"
   },
   "outputs": [],
   "source": [
    "# Fill in the line below: get names of columns with missing values\n",
    "cols_with_missing = [cols for cols in X.columns if X[cols].isnull().any()] # Your code here\n",
    "\n",
    "# Fill in the lines below: drop columns in training and validation data\n",
    "reduced_X_train = X_train.drop(columns=cols_with_missing)\n",
    "reduced_X_valid = X_valid.drop(columns=cols_with_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Knt3kspyR6V"
   },
   "source": [
    "Run the next code cell without changes to obtain the MAE for this approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "wPpQLpk8yQHf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (Drop columns with missing values):\n",
      "16367.230342465757\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE (Drop columns with missing values):\")\n",
    "print(score_dataset(reduced_X_train, reduced_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bv9A2d8_yVed"
   },
   "source": [
    "# Step 3: Imputation\n",
    "\n",
    "### Part A\n",
    "\n",
    "Use the next code cell to impute missing values with the mean value along each column.  Set the preprocessed DataFrames to `imputed_X_train` and `imputed_X_valid`.  Make sure that the column names match those in `X_train` and `X_valid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "QX5AStU7yUD6"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Fill in the lines below: imputation\n",
    "my_imputer = SimpleImputer() # Your code here\n",
    "imputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\n",
    "imputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid))\n",
    "\n",
    "# Fill in the lines below: imputation removed column names; put them back\n",
    "imputed_X_train.columns = X_train.columns\n",
    "imputed_X_valid.columns = X_valid.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tbp0ksDlybpQ"
   },
   "source": [
    "Run the next code cell without changes to obtain the MAE for this approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "MNuMI8B_yYa_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (Imputation):\n",
      "16657.755650684932\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE (Imputation):\")\n",
    "print(score_dataset(imputed_X_train, imputed_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "itmjxto-yd3e"
   },
   "source": [
    "### Part B\n",
    "\n",
    "Compare the MAE from each approach.  Does anything surprise you about the results?  Why do you think one approach performed better than the other?\n",
    "\n",
    "#####Write your answer to the above question in a new text box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "39pGYv8uy60q"
   },
   "source": [
    "##Write your answer here : In this case the method of dropping the columns with missing values preformed silghtly better then imputations, it might be because of the following reasons:\n",
    "\n",
    "1.) Our training data was very small, it had only 1168 rows but it had 36 columns out of which only 3 columns had missing values and it may be that those 3 columns do not contain significant information, so dropping those 3 columns out of 36 columns is not a bad idea.\n",
    "\n",
    "2.) Imputed values differ from the exact values, so imputation might sometimes lead to overfitting especially when our training data has very less number of rows. On the other hand dropping the columns with missing values simplify our model so that it can learn properly from the underlying patterns thus mitigating the chances of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wQGnj_sQy4GE"
   },
   "source": [
    "# Step 4: Generate test predictions\n",
    "\n",
    "In this final step, you'll use any approach of your choosing to deal with missing values.  Once you've preprocessed the training and validation features, you'll train and evaluate a random forest model.  Then, you'll preprocess the test data before generating predictions that can be submitted to the competition!\n",
    "\n",
    "### Part A\n",
    "\n",
    "Use the next code cell to preprocess the training and validation data.  Set the preprocessed DataFrames to `final_X_train` and `final_X_valid`.  **You can use any approach of your choosing here!**  in order for this step to be marked as correct, you need only ensure:\n",
    "- the preprocessed DataFrames have the same number of columns,\n",
    "- the preprocessed DataFrames have no missing values,\n",
    "- `final_X_train` and `y_train` have the same number of rows, and\n",
    "- `final_X_valid` and `y_valid` have the same number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "bQ3HMaAMy4f_"
   },
   "outputs": [],
   "source": [
    "# Preprocessed training and validation features\n",
    "final_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\n",
    "final_X_valid = pd.DataFrame(my_imputer.transform(X_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SBkZY150zHVH"
   },
   "source": [
    "Run the next code cell to train and evaluate a random forest model.  (*Note that we don't use the `score_dataset()` function above, because we will soon use the trained model to generate test predictions!*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "aRD5rM16zDdY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (Your approach):\n",
      "16657.755650684932\n"
     ]
    }
   ],
   "source": [
    "# Define and fit model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "model.fit(final_X_train, y_train)\n",
    "\n",
    "# Get validation predictions and MAE\n",
    "preds_valid = model.predict(final_X_valid)\n",
    "print(\"MAE (Your approach):\")\n",
    "print(mean_absolute_error(y_valid, preds_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FY2QOsx7zLPX"
   },
   "source": [
    "### Part B\n",
    "\n",
    "Use the next code cell to preprocess your test data.  Make sure that you use a method that agrees with how you preprocessed the training and validation data, and set the preprocessed test features to `final_X_test`.\n",
    "\n",
    "Then, use the preprocessed test features and the trained model to generate test predictions in `preds_test`.\n",
    "\n",
    "In order for this step to be marked correct, you need only ensure:\n",
    "- the preprocessed test DataFrame has no missing values, and\n",
    "- `final_X_test` has the same number of rows as `X_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "3htLrd3zzJff"
   },
   "outputs": [],
   "source": [
    "# Fill in the line below: preprocess test data\n",
    "final_X_test = pd.DataFrame(my_imputer.fit_transform(X_test))\n",
    "\n",
    "# Fill in the line below: get test predictions\n",
    "preds_test = model.predict(final_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5fAUKCVFzUno"
   },
   "source": [
    "Run the next code cell without changes to save your results to a CSV file that can be submitted directly to the competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "aSN6Gos1zU6-"
   },
   "outputs": [],
   "source": [
    "# Save test predictions to file\n",
    "output = pd.DataFrame({'Id': X_test.index,\n",
    "                       'SalePrice': preds_test})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOqTb9IX0YxYtaVe/cUibIp",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
